{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 4\n",
    "### Juan Esteban Arboleda\n",
    "### Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de los archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import nltk\n",
    "from tensorflow import keras\n",
    "from gensim.models import KeyedVectors\n",
    "from IPython.display import display_html\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = '../data/Shakespeare'\n",
    "jane_austen = '../data/JaneAusten'\n",
    "lovecraft = '../data/Lovecraft'\n",
    "\n",
    "def load_books(path):\n",
    "    \"\"\"\n",
    "    Carga los libros de un autor y los devuelve en una lista\n",
    "    Params:\n",
    "    ------\n",
    "    path: str\n",
    "        Path de la carpeta que contiene los libros\n",
    "    Returns:\n",
    "    -------\n",
    "    books: list\n",
    "        Lista de strings, cada uno representa un libro\n",
    "    \"\"\"\n",
    "    books = []\n",
    "    book_paths = os.listdir(path)\n",
    "    for book_path in book_paths:\n",
    "        book = open(path + '/' + book_path, 'r', encoding='utf-8')\n",
    "        books.append(book.read())\n",
    "        book.close()\n",
    "    return books\n",
    "shakespeare_books = load_books(shakespeare)\n",
    "jane_austen_books = load_books(jane_austen)\n",
    "lovecraft_books = load_books(lovecraft)\n",
    "\n",
    "books = {'shakespeare': shakespeare_books, 'jane_austen': jane_austen_books, 'lovecraft': lovecraft_books}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentence:str)->str:\n",
    "    \"\"\"\n",
    "    Normalize a sentence by lowercasing it and removing non alphanumeric characters\n",
    "    Params:\n",
    "    -------\n",
    "        sentence: sentence to normalize\n",
    "    Returns:\n",
    "    --------\n",
    "        sentence: normalized sentence\n",
    "    \"\"\"\n",
    "\n",
    "    sentence = re.sub(r\"[^(a-zA-Z0-9\\s)]\", \" \", sentence).lower().replace(\"\\n\", \" \")\n",
    "\n",
    "    return sentence\n",
    "\n",
    "for author in books.keys():\n",
    "    for i in range(len(books[author])):\n",
    "        books[author][i] = normalize(books[author][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document:str)->list:\n",
    "    \"\"\"\n",
    "    Tokenize a document\n",
    "    Params:\n",
    "    -------\n",
    "        document: document to tokenize  \n",
    "    Returns:\n",
    "    --------\n",
    "        tokens: list of tokens\n",
    "    \"\"\"\n",
    "    return gensim.utils.simple_preprocess(document, deacc=True)\n",
    "\n",
    "books_list =[]\n",
    "for author in books.keys():\n",
    "    for book in books[author]:\n",
    "        books_list.append(tokenize(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo creado y guardado\n"
     ]
    }
   ],
   "source": [
    "PATH_EMBEDDINGS_50 = \"../models/embeddings_50.model\"\n",
    "embeddings_50 = gensim.models.Word2Vec(books_list, vector_size=50, window=4, min_count=2, workers=10)\n",
    "if not os.path.exists(PATH_EMBEDDINGS_50):\n",
    "    embeddings_50.train(books_list,total_examples=len(books_list),epochs=100)\n",
    "\n",
    "    embeddings_50.save(PATH_EMBEDDINGS_50)\n",
    "    print(\"Modelo creado y guardado\")\n",
    "else:\n",
    "    embeddings_50 = gensim.models.Word2Vec.load(PATH_EMBEDDINGS_50)\n",
    "    print(\"Modelo cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('juliet', 0.7407148480415344),\n",
       " ('tybalt', 0.7117395997047424),\n",
       " ('benvolio', 0.7086887359619141),\n",
       " ('nurse', 0.6875778436660767),\n",
       " ('holy', 0.5993909239768982),\n",
       " ('perchance', 0.5835080742835999),\n",
       " ('friar', 0.5627440810203552),\n",
       " ('slain', 0.562606930732727),\n",
       " ('peter', 0.5613883137702942),\n",
       " ('mercutio', 0.5509238839149475)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_50.wv.most_similar('romeo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.6777352690696716),\n",
       " ('guildenstern', 0.6111937761306763),\n",
       " ('duncan', 0.607665479183197),\n",
       " ('cornelius', 0.5702257752418518),\n",
       " ('surveying', 0.5673308968544006),\n",
       " ('thrift', 0.5583811402320862),\n",
       " ('queen', 0.5492324233055115),\n",
       " ('hecate', 0.5105694532394409),\n",
       " ('meantime', 0.5000250339508057),\n",
       " ('vanish', 0.4956698715686798)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = (embeddings_50.wv['king'] - embeddings_50.wv['man']) + (embeddings_50.wv['queen'])\n",
    "embeddings_50.wv.most_similar(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_100 = gensim.models.Word2Vec(books_list, size=100, window=4, min_count=2, workers=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
