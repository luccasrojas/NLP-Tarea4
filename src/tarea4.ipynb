{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 4\n",
    "### Juan Esteban Arboleda\n",
    "### Luccas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de los archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import nltk\n",
    "from tensorflow import keras\n",
    "from gensim.models import KeyedVectors\n",
    "from IPython.display import display_html\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = '../data/Shakespeare'\n",
    "jane_austen = '../data/JaneAusten'\n",
    "lovecraft = '../data/Lovecraft'\n",
    "\n",
    "def load_books(path):\n",
    "    \"\"\"\n",
    "    Carga los libros de un autor y los devuelve en una lista\n",
    "    Params:\n",
    "    ------\n",
    "    path: str\n",
    "        Path de la carpeta que contiene los libros\n",
    "    Returns:\n",
    "    -------\n",
    "    books: list\n",
    "        Lista de strings, cada uno representa un libro\n",
    "    \"\"\"\n",
    "    books = []\n",
    "    book_paths = os.listdir(path)\n",
    "    for book_path in book_paths:\n",
    "        book = open(path + '/' + book_path, 'r', encoding='utf-8')\n",
    "        books.append(book.read())\n",
    "        book.close()\n",
    "    return books\n",
    "shakespeare_books = load_books(shakespeare)\n",
    "jane_austen_books = load_books(jane_austen)\n",
    "lovecraft_books = load_books(lovecraft)\n",
    "\n",
    "books = {'shakespeare': shakespeare_books, 'jane_austen': jane_austen_books, 'lovecraft': lovecraft_books}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentence:str)->str:\n",
    "    \"\"\"\n",
    "    Normalize a sentence by lowercasing it and removing non alphanumeric characters\n",
    "    Params:\n",
    "    -------\n",
    "        sentence: sentence to normalize\n",
    "    Returns:\n",
    "    --------\n",
    "        sentence: normalized sentence\n",
    "    \"\"\"\n",
    "\n",
    "    sentence = re.sub(r\"[^(a-zA-Z0-9\\s)]\", \" \", sentence).lower().replace(\"\\n\", \" \")\n",
    "\n",
    "    return sentence\n",
    "\n",
    "for author in books.keys():\n",
    "    for i in range(len(books[author])):\n",
    "        books[author][i] = normalize(books[author][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document:str)->list:\n",
    "    \"\"\"\n",
    "    Tokenize a document\n",
    "    Params:\n",
    "    -------\n",
    "        document: document to tokenize  \n",
    "    Returns:\n",
    "    --------\n",
    "        tokens: list of tokens\n",
    "    \"\"\"\n",
    "    return gensim.utils.simple_preprocess(document, deacc=True)\n",
    "\n",
    "books_list =[]\n",
    "for author in books.keys():\n",
    "    for book in books[author]:\n",
    "        books_list.append(tokenize(book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo creado y guardado\n"
     ]
    }
   ],
   "source": [
    "PATH_EMBEDDINGS_50 = \"../models/embeddings_50.model\"\n",
    "embeddings_50 = gensim.models.Word2Vec(books_list, vector_size=50, window=4, min_count=2, workers=10)\n",
    "if not os.path.exists(PATH_EMBEDDINGS_50):\n",
    "    embeddings_50.train(books_list,total_examples=len(books_list),epochs=100)\n",
    "\n",
    "    embeddings_50.save(PATH_EMBEDDINGS_50)\n",
    "    print(\"Modelo creado y guardado\")\n",
    "else:\n",
    "    embeddings_50 = gensim.models.Word2Vec.load(PATH_EMBEDDINGS_50)\n",
    "    print(\"Modelo cargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('expressly', 0.718009889125824),\n",
       " ('coxcombs', 0.6330082416534424),\n",
       " ('slave', 0.6319321393966675),\n",
       " ('rung', 0.6313157677650452),\n",
       " ('everlasting', 0.6285082697868347)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_50.wv.most_similar('cat', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.695233941078186),\n",
       " ('woman', 0.47210273146629333),\n",
       " ('named', 0.46514174342155457)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship = embeddings_50.wv['queen'] - embeddings_50.wv['king'] + embeddings_50.wv['man']\n",
    "\n",
    "# Encuentra palabras más similares a la relación calculada\n",
    "embeddings_50.wv.most_similar([relationship], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_100 = gensim.models.Word2Vec(books_list, size=100, window=4, min_count=2, workers=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
